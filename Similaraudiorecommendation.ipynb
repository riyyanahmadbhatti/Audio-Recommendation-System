{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of fma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/parse.c:do_readahead():1099] warning: Cannot read next header, a one-frame stream? Duh...\n",
      "/tmp/ipykernel_3177/2254228980.py:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audiofile, sr=None)\n",
      "/home/riyyan/.local/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing fma_sample/001/001486.mp3: \n",
      "Normalized features have been saved to normalizedfeaturessample.csv\n",
      "Normalized features have been stored in MongoDB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import csv\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def extract_features(audiofile):\n",
    "\n",
    "    y, sr = librosa.load(audiofile, sr=None) \n",
    "    \n",
    "    #extract mfccs \n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccsmean = np.mean(mfccs, axis=1)\n",
    "    \n",
    "    #extract spectral centroid\n",
    "    spectralcentroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    spectralcentroidmean = np.mean(spectralcentroid)\n",
    "    \n",
    "    #extract zero crossing rate\n",
    "    zerocrossingrate = librosa.feature.zero_crossing_rate(y)[0]\n",
    "    zerocrossingratemean = np.mean(zerocrossingrate)\n",
    "    \n",
    "    features = np.concatenate([mfccsmean, [spectralcentroidmean], [zerocrossingratemean]])\n",
    "    \n",
    "    #also adding the filename in the csv\n",
    "    filename = os.path.basename(audiofile)\n",
    "    \n",
    "    return filename, features\n",
    "\n",
    "def getaudiofiles(directory):\n",
    "    audiofiles = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp3'):\n",
    "                audiofiles.append(os.path.join(root, file))\n",
    "    return audiofiles\n",
    "\n",
    "mainaudiofolder = 'fma_sample'\n",
    "\n",
    "allfeatures = []\n",
    "\n",
    "#iterating over all subfolders\n",
    "for folder in os.listdir(mainaudiofolder):\n",
    "    subfolder = os.path.join(mainaudiofolder, folder)\n",
    "    if os.path.isdir(subfolder):\n",
    "        #obtaining all files from the subfolder\n",
    "        audiofiles = getaudiofiles(subfolder)\n",
    "        #going over each single file\n",
    "        for audiofile in audiofiles:\n",
    "            try:\n",
    "                filename, features = extract_features(audiofile)\n",
    "                allfeatures.append((filename, features))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {audiofile}: {e}\")\n",
    "\n",
    "#normalizing all features \n",
    "scaler = StandardScaler()\n",
    "normalizedfeatures = scaler.fit_transform(np.array([features for _, features in allfeatures]))\n",
    "\n",
    "#writing data to csv \n",
    "outputfile = 'normalizedfeaturessample.csv'\n",
    "with open(outputfile, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write column names\n",
    "    writer.writerow(['Audio File', 'MFCC1', 'MFCC2', 'MFCC3', 'MFCC4', 'MFCC5', 'MFCC6', 'MFCC7', 'MFCC8', 'MFCC9', 'MFCC10', 'MFCC11', 'MFCC12', 'MFCC13', 'Spectral Centroid', 'Zero Crossing Rate'])\n",
    "    # Write normalized features\n",
    "    for file_name, features in allfeatures:\n",
    "        writer.writerow([file_name, *features])\n",
    "\n",
    "print(f\"Normalized features have been saved to {outputfile}\")\n",
    "\n",
    "#connecting to mongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['audio_features']\n",
    "collection = db['features']\n",
    "\n",
    "#inserting data into mongodb\n",
    "for filename, features in allfeatures:\n",
    "    doc = {'file name': filename, 'features': features.tolist()}\n",
    "    collection.insert_one(doc)\n",
    "\n",
    "print(\"Normalized features have been stored in MongoDB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation using spark api dataframe on the preprocessed csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/12 15:10:59 WARN Utils: Your hostname, riyyan-HP-ENVY-x360-2-in-1-Laptop-13-bf0xxx resolves to a loopback address: 127.0.1.1; using 192.168.100.254 instead (on interface wlo1)\n",
      "24/05/12 15:10:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/12 15:10:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AudioFileSimilarity\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"normalizedfeaturessample.csv\", header=True)\n",
    "\n",
    "#convert features to double type\n",
    "for featurecols in df.columns[1:]:\n",
    "    df = df.withColumn(featurecols, col(featurecols).cast(DoubleType()))\n",
    "\n",
    "#function to calculate similarity by finding euclideon distance btw the two features\n",
    "def calculatesimilarity(features1, features2):\n",
    "    #calculating the sum of squared differences between features\n",
    "    squared_diff_sum = sum((x - y) ** 2 for x, y in zip(features1, features2))\n",
    "    #return the square root of the sum of squared differences\n",
    "    return squared_diff_sum ** 0.5\n",
    "\n",
    "#calculating similarity of every pair in the folder \n",
    "similarities = {}\n",
    "for row1 in df.collect():\n",
    "    audiofile1 = row1[\"Audio File\"]\n",
    "    features1 = [row1[col] for col in df.columns[1:]]\n",
    "    similarities[audiofile1] = []\n",
    "    for row2 in df.collect():\n",
    "        audiofile2 = row2[\"Audio File\"]\n",
    "        features2 = [row2[col] for col in df.columns[1:]]\n",
    "        similarity = calculatesimilarity(features1, features2)\n",
    "        similarities[audiofile1].append((audiofile2, similarity))\n",
    "\n",
    "\n",
    "outputdata = []\n",
    "for audiofile, similarfiles in similarities.items():\n",
    "    similarfiles.sort(key=lambda x: x[1])  #sorting by similarity\n",
    "    similarfilesstr = \",\".join(f\"{file}:{similarity:.2f}\" for file, similarity in similarfiles[:5])  #only showing the top 5 similarity pairs\n",
    "    outputdata.append((audiofile, similarfilesstr))\n",
    "\n",
    "#storing the data into csv\n",
    "outputdf = spark.createDataFrame(outputdata, [\"Audio File\", \"Similar Files\"])\n",
    "outputdf.coalesce(1).write.csv(\"similaraudiosample.csv\", header=True)\n",
    "\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
